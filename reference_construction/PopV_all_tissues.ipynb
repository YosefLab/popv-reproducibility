{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36a6b4a-5398-4d39-b547-3f9fbc7593f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 14:38:34.989326: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-30 14:38:37.173435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-30 14:38:37.173613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-30 14:38:37.173631: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/eecs/cergen/anaconda3/envs/PopV/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, '/data/yosef2/users/can/PopV/PopV')\n",
    "import popv\n",
    "import anndata\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87f6f2ce-0c29-4e9b-ae20-0f3ac61e5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "res = requests.get(\"https://zenodo.org/api/records/7587774\")\n",
    "tissue_download_path = {ind['key'][3:-14]:ind['links']['self'] for ind in res.json()['files']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eec69ad-e9fd-4a4d-9e86-0ee91dfc17d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading\n",
      "--2023-01-30 14:38:53--  https://www.dropbox.com/s/mrf8y7emfupo4he/LCA.h5ad?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/dl/mrf8y7emfupo4he/LCA.h5ad [following]\n",
      "--2023-01-30 14:38:53--  https://www.dropbox.com/s/dl/mrf8y7emfupo4he/LCA.h5ad\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucd8169d1d68f4fe72546f0366d1.dl.dropboxusercontent.com/cd/0/get/B1kqB2pTz7_2-w1FXiUmM2JHNysH2tqDypjRRmiIEEF--A2ATu9cfmXSZwnwewtY86tIPDBFgH66TBW9WhWUHFkSVAB6RnJfVUBKE7FFACkbZI7XdbXo19m9k_nnGwgHo5EM92LZMKBxnALwW8HC8xkGDLbBQF5I-kudt_dKaX5j-NWKFYGwtq8DC09w_vY5Z0g/file?dl=1# [following]\n",
      "--2023-01-30 14:38:53--  https://ucd8169d1d68f4fe72546f0366d1.dl.dropboxusercontent.com/cd/0/get/B1kqB2pTz7_2-w1FXiUmM2JHNysH2tqDypjRRmiIEEF--A2ATu9cfmXSZwnwewtY86tIPDBFgH66TBW9WhWUHFkSVAB6RnJfVUBKE7FFACkbZI7XdbXo19m9k_nnGwgHo5EM92LZMKBxnALwW8HC8xkGDLbBQF5I-kudt_dKaX5j-NWKFYGwtq8DC09w_vY5Z0g/file?dl=1\n",
      "Resolving ucd8169d1d68f4fe72546f0366d1.dl.dropboxusercontent.com (ucd8169d1d68f4fe72546f0366d1.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
      "Connecting to ucd8169d1d68f4fe72546f0366d1.dl.dropboxusercontent.com (ucd8169d1d68f4fe72546f0366d1.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 354684075 (338M) [application/binary]\n",
      "Saving to: ‚Äòdownloaded_ts_data_popv/LCA.h5ad‚Äô\n",
      "\n",
      "downloaded_ts_data_ 100%[===================>] 338.25M  64.2MB/s    in 5.3s    \n",
      "\n",
      "2023-01-30 14:38:59 (63.7 MB/s) - ‚Äòdownloaded_ts_data_popv/LCA.h5ad‚Äô saved [354684075/354684075]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_file ={'source': 'wget', 'path': 'downloaded_ts_data_popv/LCA.h5ad', 'link': 'https://www.dropbox.com/s/mrf8y7emfupo4he/LCA.h5ad?dl=1'}\n",
    "\n",
    "if input_file['source']== 'gdrive':\n",
    "  # OPTION 1: Connect to Google Drive\n",
    "  # This is the recomended method especially for large datasets\n",
    "  from google.colab import drive    \n",
    "  drive.mount('/content/drive')\n",
    "  query_adata = anndata.read(input_file['path'])\n",
    "elif input_file['source'] == 'local':\n",
    "  # OPTION 2: Uploading data manually\n",
    "  # Click the folder icon on the left navigation bar, and select the upload icon\n",
    "  # Note: Manually uploaded data is automatically deleted when the colab session ends\n",
    "  # This is not recommended if your dataset is very large\n",
    "  query_adata = anndata.read(input_file['path'])\n",
    "else:\n",
    "  # OPTION 3: Downloading from the cloud (Dropbox, AWS, Google Drive, etc)\n",
    "  # Google Colab supports wget, curl, and gdown commands\n",
    "  # It is recommended to download the data into Google Drive and read from there.\n",
    "  # This way your data will be persistent.\n",
    "  print('downloading')\n",
    "  try:\n",
    "    !wget -O {input_file['path']} {input_file['link']}\n",
    "    query_adata = anndata.read(input_file['path'])\n",
    "  except:\n",
    "    raise Exception(f'Default download failed with wget. Use custom downloader or check provided link ' + input_file['link'])\n",
    "    \n",
    "query_adata.obs_names_make_unique()\n",
    "query_adata.var_names = query_adata.var_names.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fdf8ad9-707f-4356-901b-fc9702296bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_adata = sc.read('downloaded_ts_data_popv/LCA.h5ad')\n",
    "query_adata = query_adata[query_adata.obs_names[0:5]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4585b3b3-2c3b-4a63-aee4-523ef5814efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs √ó n_vars = 5 √ó 23681\n",
       "    obs: 'method', 'donor', 'cell_ontology_type', 'donor_method', 'cell_ontology_id'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9fd481-cea1-437e-bdd9-6fa24079602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following parameters are specific to Tabula Sapiens dataset\n",
    "ref_labels_key='cell_ontology_class'\n",
    "ref_batch_key = 'donor_assay'\n",
    "\n",
    "query_batch_key = 'donor_method'\n",
    "query_labels_key=None\n",
    "unknown_celltype_label='unknown'\n",
    "\n",
    "# Folder structure for files and models.\n",
    "data_dir = 'downloaded_ts_data_popv/'\n",
    "model_dir = 'pretrained_predictors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "717cedaa-4b0f-4264-bb6e-a9be263da97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from popv.preprocessing import Process_Query\n",
    "from popv.annotation import annotate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f61c171-87dd-479e-bfe1-095c27894f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.figdir = model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0efd730b-00a4-4c16-86fa-855b7d937fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e62e3-ce93-405a-9877-d4b58475eaed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salivary_Gland https://zenodo.org/api/files/0dfd03a7-d45c-43cd-b79a-779bbac161df/TS_Salivary_Gland_filtered.h5ad\n",
      "--2023-01-30 23:40:38--  https://zenodo.org/api/files/0dfd03a7-d45c-43cd-b79a-779bbac161df/TS_Salivary_Gland_filtered.h5ad\n",
      "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
      "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1142910098 (1.1G) [application/octet-stream]\n",
      "Saving to: ‚Äòdownloaded_ts_data_popv/TS_Salivary_Gland.h5ad‚Äô\n",
      "\n",
      "downloaded_ts_data_   4%[                    ]  47.15M  22.2KB/s    in 8m 55s  \n",
      "\n",
      "2023-01-30 23:49:34 (90.3 KB/s) - Read error at byte 49445860/1142910098 (Connection reset by peer). Retrying.\n",
      "\n",
      "--2023-01-30 23:49:35--  (try: 2)  https://zenodo.org/api/files/0dfd03a7-d45c-43cd-b79a-779bbac161df/TS_Salivary_Gland_filtered.h5ad\n",
      "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 206 Partial Content\n",
      "Length: 1142910098 (1.1G), 1093464238 (1.0G) remaining [application/octet-stream]\n",
      "Saving to: ‚Äòdownloaded_ts_data_popv/TS_Salivary_Gland.h5ad‚Äô\n",
      "\n",
      "downloaded_ts_data_ 100%[===================>]   1.06G  1.28MB/s    in 30m 2s  \n",
      "\n",
      "2023-01-31 00:19:38 (593 KB/s) - ‚Äòdownloaded_ts_data_popv/TS_Salivary_Gland.h5ad‚Äô saved [1142910098/1142910098]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 500 per label\n",
      "Saving celltypist results to adata.obs[\"popv_celltypist_prediction\"]\n",
      "üç≥ Preparing data before training\n",
      "‚öñÔ∏è Scaling input data\n",
      "üèãÔ∏è Training data using logistic regression\n",
      "‚úÖ Model training done!\n",
      "üî¨ Input data has 27199 cells and 4000 genes\n",
      "üîó Matching reference genes in the model\n",
      "üß¨ 4000 features used for prediction\n",
      "‚öñÔ∏è Scaling input data\n",
      "üñãÔ∏è Predicting labels\n",
      "‚úÖ Prediction done!\n",
      "üëÄ Can not detect a neighborhood graph, will construct one before the over-clustering\n",
      "‚õìÔ∏è Over-clustering input data with resolution set to 15\n",
      "üó≥Ô∏è Majority voting the predictions\n",
      "‚úÖ Majority voting done!\n",
      "Integrating data with bbknn\n",
      "Saving knn on bbknn results to adata.obs[\"popv_knn_on_bbknn_prediction\"]\n",
      "Saving UMAP of bbknn results to adata.obs[\"X_bbknn_umap_popv\"]\n",
      "Integrating data with scanorama\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 genes among all datasets\n",
      "[[0.         0.24067403 0.01081731 0.05438993]\n",
      " [0.         0.         0.50721154 0.15187218]\n",
      " [0.         0.         0.         0.37019231]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Processing datasets (1, 2)\n",
      "Processing datasets (2, 3)\n",
      "Processing datasets (0, 1)\n",
      "Processing datasets (1, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving knn on scanorama results to adata.obs[\"popv_knn_on_scanorama_prediction\"]\n",
      "Saving UMAP of scanorama results to adata.obs[\"X_scanorama_umap_popv\"]\n",
      "Integrating data with scvi\n",
      "Training scvi offline.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [10:12<00:00,  5.12s/it, loss=1.62e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=147` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/147: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 147/147 [10:12<00:00,  4.17s/it, loss=1.62e+03, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving knn on scvi results to adata.obs[\"popv_knn_on_scvi_prediction\"]\n",
      "Saving UMAP of scvi results to adata.obs[\"X_scvi_umap_popv\"]\n",
      "Computing Onclass. Storing prediction in adata.obs[\"popv_onclass_prediction\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost after epoch 1: loss:5.751677 acc: 0.965 auc: 1.000 auprc: 0.996\n",
      "Training cost after epoch 2: loss:3.019369 acc: 0.990 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 3: loss:2.038338 acc: 0.994 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 4: loss:1.481948 acc: 0.998 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 5: loss:1.094697 acc: 1.000 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 6: loss:0.812251 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 7: loss:0.607495 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 8: loss:0.462070 acc: 0.994 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 9: loss:0.361137 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 10: loss:0.288362 acc: 0.998 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 11: loss:0.234730 acc: 0.997 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 12: loss:0.209555 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 13: loss:0.171058 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 14: loss:0.156149 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 15: loss:0.140317 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 16: loss:0.130673 acc: 0.996 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 17: loss:0.124237 acc: 0.998 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 18: loss:0.123554 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 19: loss:0.112678 acc: 0.998 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 20: loss:0.106631 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 21: loss:0.105201 acc: 0.997 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 22: loss:0.104459 acc: 0.998 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 23: loss:0.102981 acc: 0.997 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 24: loss:0.105975 acc: 1.000 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 25: loss:0.096768 acc: 0.996 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 26: loss:0.110417 acc: 0.974 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 27: loss:0.110011 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 28: loss:0.101130 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 29: loss:0.095491 acc: 0.999 auc: 1.000 auprc: 1.000\n",
      "Training cost after epoch 30: loss:0.092792 acc: 0.998 auc: 1.000 auprc: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing random forest classifier. Storing prediction in adata.obs[\"popv_rf_prediction\"]\n",
      "Integrating data with scANVI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File pretrained_predictors/Salivary_Gland_pretrained/\u001b[35m/scvi/\u001b[0m\u001b[95mmodel.pt\u001b[0m already downloaded                    \n",
      "\u001b[34mINFO    \u001b[0m Training for \u001b[1;36m20\u001b[0m epochs.                                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:57<00:00,  2.88s/it, loss=1.75e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:57<00:00,  2.88s/it, loss=1.75e+03, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving scanvi label prediction to adata.obs[\"popv_scanvi_prediction\"]\n",
      "Saving UMAP of scanvi results to adata.obs[\"X_scanvi_umap_popv\"]\n",
      "Computing support vector machine. Storing prediction in adata.obs[\"popv_svm_prediction\"]\n",
      "Using predictions ['popv_celltypist_prediction', 'popv_knn_on_bbknn_prediction', 'popv_knn_on_scanorama_prediction', 'popv_knn_on_scvi_prediction', 'popv_onclass_prediction', 'popv_rf_prediction', 'popv_scanvi_prediction', 'popv_svm_prediction'] for PopV consensus\n",
      "... storing '_batch_annotation' as categorical\n",
      "... storing '_labels_annotation' as categorical\n",
      "... storing 'popv_knn_on_bbknn_prediction' as categorical\n",
      "... storing 'popv_knn_on_scanorama_prediction' as categorical\n",
      "... storing 'popv_knn_on_scvi_prediction' as categorical\n",
      "... storing '_labels_annotation_cell_ontology_id' as categorical\n",
      "... storing 'popv_onclass_prediction' as categorical\n",
      "... storing 'onclass_seen' as categorical\n",
      "... storing 'popv_rf_prediction' as categorical\n",
      "... storing 'popv_scanvi_prediction' as categorical\n",
      "... storing 'popv_svm_prediction' as categorical\n",
      "... storing 'popv_majority_vote_prediction' as categorical\n",
      "... storing 'popv_prediction' as categorical\n",
      "... storing 'popv_parent' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: saving figure to file pretrained_predictors/umapSalivary_Gland.pdf\n",
      "Small_Intestine https://zenodo.org/api/files/0dfd03a7-d45c-43cd-b79a-779bbac161df/TS_Small_Intestine_filtered.h5ad\n",
      "--2023-01-31 00:46:55--  https://zenodo.org/api/files/0dfd03a7-d45c-43cd-b79a-779bbac161df/TS_Small_Intestine_filtered.h5ad\n",
      "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
      "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 345399676 (329M) [application/octet-stream]\n",
      "Saving to: ‚Äòdownloaded_ts_data_popv/TS_Small_Intestine.h5ad‚Äô\n",
      "\n",
      "                dow  95%[==================> ] 315.19M  1.29MB/s    eta 19s    "
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "tissue options: \n",
    "\n",
    "\"\"\"\n",
    "# Done \n",
    "#  - Following label not in celltype_dict  intestinal transient amplifying cell\n",
    "# Lung - No path between capillary aerocyte and cell.\n",
    "\n",
    "finished = []\n",
    "\n",
    "for tissue in ['Salivary_Gland', 'Small_Intestine']: #tissue_download_path.keys()::\n",
    "    if tissue in finished:\n",
    "        print(f'{tissue} already finished. Skipping recomputation!')\n",
    "        continue\n",
    "    refdata_url = tissue_download_path[tissue]\n",
    "    print(tissue, refdata_url)\n",
    "    if refdata_url is None:\n",
    "        continue\n",
    "    # Download reference dataset\n",
    "    output_fn = data_dir + f'TS_{tissue}.h5ad'\n",
    "    !wget -O $output_fn $refdata_url\n",
    "    ref_adata = anndata.read(output_fn)\n",
    "\n",
    "    min_celltype_size = np.min(ref_adata.obs.groupby(ref_labels_key).size())\n",
    "    n_samples_per_label = np.max((min_celltype_size, 500))\n",
    "\n",
    "    adata = Process_Query(\n",
    "            query_adata,\n",
    "            ref_adata,\n",
    "            query_labels_key=query_labels_key,\n",
    "            query_batch_key=query_batch_key,\n",
    "            ref_labels_key=ref_labels_key,\n",
    "            ref_batch_key=ref_batch_key,\n",
    "            \n",
    "            unknown_celltype_label=unknown_celltype_label,\n",
    "            save_path_trained_models=model_dir+tissue+'_pretrained/',\n",
    "            prediction_mode='retrain', # 'fast' mode gives fast results (does not include BBKNN and Scanorama and makes more inaccurate errors)\n",
    "            n_samples_per_label=n_samples_per_label,\n",
    "            use_gpu=2,\n",
    "            compute_embedding=True,\n",
    "            hvg=4000\n",
    "        ).adata\n",
    "    annotate_data(adata, save_path=None)\n",
    "    adata.obsm['X_umap'] = adata.obsm['X_scanvi_umap_popv']\n",
    "    _ = sc.pl.umap(adata, color=[ref_labels_key, ref_batch_key], ncols=1, save=tissue+'.pdf', frameon=False, show=False)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf11c3-d65b-4c33-b5d3-fe6bbb82148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scvi\n",
    "import gc\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81c9d5-e767-448b-985c-0a230f6a846c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tissues = ['Blood', 'Bone_Marrow', 'Fat', 'Heart', 'Kidney', 'Large_Intestine', 'Liver', 'Lung', 'Lymph_Node', 'Mammary', 'Muscle', 'Pancreas',\n",
    "           'Prostate', 'Salivary_Gland', 'Skin', 'Small_Intestine', 'Spleen', 'Thymus', 'Trachea', 'Vasculature']\n",
    "\n",
    "\"\"\" \n",
    "tissue options: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Done \n",
    "#  - Following label not in celltype_dict  intestinal transient amplifying cell\n",
    "# Lung - No path between capillary aerocyte and cell.\n",
    "\n",
    "for tissue in tissues:\n",
    "    adata = sc.read(f\"pretrained_model_all_latest/trained_models_{tissue}/adata.h5ad\")\n",
    "    scvi.model.CondSCVI.setup_anndata(\n",
    "        adata,\n",
    "        labels_key=\"_labels_annotation\",\n",
    "        layer=\"scvi_counts\",\n",
    "    )\n",
    "    \n",
    "    condscvi_model = scvi.model.CondSCVI(\n",
    "        adata,\n",
    "        n_latent=5,\n",
    "        n_layers=2,\n",
    "        dropout_rate=0.05,\n",
    "        weight_obs=False\n",
    "    )\n",
    "\n",
    "    condscvi_model.train(max_epochs=200, train_size=1.0, batch_size=batch_size)\n",
    "    condscvi_model.save(f\"pretrained_model_all_latest/trained_models_{tissue}/condscvi\", overwrite=True, save_anndata=False)\n",
    "    \n",
    "    scvi.external.RNAStereoscope.setup_anndata(\n",
    "        adata,\n",
    "        labels_key = \"_labels_annotation\",\n",
    "        layer = \"scvi_counts\")\n",
    "    stereoscope_model = scvi.external.stereoscope.RNAStereoscope(\n",
    "        adata\n",
    "    )\n",
    "    stereoscope_model.train()\n",
    "    stereoscope_model.save(f\"pretrained_model_all_latest/trained_models_{tissue}/rna_stereoscope\", overwrite=True, save_anndata=False)\n",
    "    \n",
    "    print('Finished ', tissue)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37a7a3-fc45-43a6-8ce6-c039bb0b0ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae45dae-05f0-4dcf-b58b-eb126df928c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tissue in tissues:\n",
    "    !tar -czvf pretrained_model_all_other_filtering/{tissue}_pretrained_ts.tar.gz -C pretrained_model_all_other_filtering/trained_models_{tissue}/ .\n",
    "    #!rm -rf pretrained_model_all_other_filtering/trained_models_{tissue}\n",
    "    !file {tissue}_pretrained_ts.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2256caba-a297-4b88-b9b1-75375cfbe1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(tissue, output_dir='', root_dir='.'):\n",
    "    \"\"\"compress dirs.\n",
    "\n",
    "    KWArgs\n",
    "    ------\n",
    "    output_file : str, default =\"archive.tar.gz\"\n",
    "    output_dir : str, default = ''\n",
    "        absolute path to output\n",
    "    root_dir='.',\n",
    "        absolute path to input root dir\n",
    "    items : list\n",
    "        list of dirs/items relative to root dir\n",
    "\n",
    "    \"\"\"\n",
    "    items = [\"pretrained_model_all/trained_models_\" + tissue]\n",
    "    print(items)\n",
    "    with tarfile.open(\"pretrained_model_all/\" + tissue + '_pretrained_ts.tar.gz', \"w\") as tar:\n",
    "        for item in items:\n",
    "            print(item)\n",
    "            tar.add(item, arcname=item)\n",
    "\n",
    "for tissue in tissues:\n",
    "    print(tissue)\n",
    "    compress(tissue=tissue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0397d-938b-4e2b-b78b-1cb3b4690e34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PopV",
   "language": "python",
   "name": "popv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
